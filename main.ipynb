{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be66f97",
   "metadata": {},
   "source": [
    "Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07c0ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# own packages\n",
    "from preprocess_data import clean_text\n",
    "from preprocess_data import lemmatize_text\n",
    "from preprocess_data import tfidf_vectorization\n",
    "from preprocess_data import count_vectorizer\n",
    "from models import model_rf_train\n",
    "from model_MultinomialNB import model_mnb_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1430f34",
   "metadata": {},
   "source": [
    "Function for reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cecb90c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get csv data\n",
    "def read_Data(path):\n",
    "\n",
    "    # Define column names\n",
    "    column_names = ['label', 'text']\n",
    "    return pd.read_csv(path, delimiter='\\t', encoding='latin-1', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1cacf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data\n",
    "data_train_val = read_Data(r\".\\data\\training_data_lowercase.csv\")           # used for train and val data\n",
    "data_test = read_Data(r\".\\data\\testing_data_lowercase_nolabels.csv\")        # data for the predictions\n",
    "\n",
    "## split data_train into train and val data\n",
    "data_train, data_val = train_test_split(data_train_val, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9317fe85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train data:\n",
      " (34152, 2)\n",
      "Shape test data:\n",
      " (9984, 2)\n",
      "Cleand text train: \n",
      " <bound method NDFrame.head of 8891                                                    []\n",
      "25115    [final, reckoning, approaches, obamas, high, c...\n",
      "26933    [illinois, budget, talks, fizzle, amid, partis...\n",
      "26971    [clinton, spokesman, ig, report, shows, clinto...\n",
      "11387    [busted, nancy, pelosi, claims, meeting, russi...\n",
      "                               ...                        \n",
      "16850                  [senate, passes, usa, freedom, act]\n",
      "6265     [oklahoma, republicans, trying, impeach, obama...\n",
      "11284    [texas, congressman, lets, screaming, leftist,...\n",
      "860      [trump, stole, idea, north, korean, propaganda...\n",
      "15795    [outrageous, nancy, pelosi, claims, obamacare,...\n",
      "Name: cleaned_text, Length: 27321, dtype: object> \n",
      "\n",
      "Cleand text test: \n",
      " <bound method NDFrame.head of 0       [copycat, muslim, terrorist, arrested, assault...\n",
      "1       [wow, chicago, protester, caught, camera, admi...\n",
      "2       [germanys, fdp, look, fill, schaeubles, big, s...\n",
      "3       [mi, school, sends, welcome, back, packet, war...\n",
      "4       [un, seeks, massive, aid, boost, amid, rohingy...\n",
      "                              ...                        \n",
      "9979    [boom, fox, news, leftist, chris, wallace, att...\n",
      "9980    [list, democrat, hypocrites, voted, filibuster...\n",
      "9981    [new, fires, ravage, rohingya, villages, north...\n",
      "9982    [meals, wheels, shuts, lyin, lefties, truth, m...\n",
      "9983    [brilliant, tucker, carlson, ayaan, hirsi, ali...\n",
      "Name: cleaned_text, Length: 9984, dtype: object> \n",
      "\n",
      "lemmatized_text train: \n",
      " <bound method NDFrame.head of 8891                                                      \n",
      "25115    final reckoning approach obamas high court nom...\n",
      "26933    illinois budget talk fizzle amid partisan entr...\n",
      "26971    clinton spokesman ig report show clinton misst...\n",
      "11387    busted nancy pelosi claim meeting russian amba...\n",
      "                               ...                        \n",
      "16850                          senate pass usa freedom act\n",
      "6265     oklahoma republican trying impeach obama dumbe...\n",
      "11284    texas congressman let screaming leftist agitat...\n",
      "860      trump stole idea north korean propaganda parod...\n",
      "15795    outrageous nancy pelosi claim obamacare honor ...\n",
      "Name: lemmatized_text, Length: 27321, dtype: object> \n",
      "\n",
      "lemmatized_text test: \n",
      " <bound method NDFrame.head of 0        copycat muslim terrorist arrested assault weapon\n",
      "1       wow chicago protester caught camera admits vio...\n",
      "2               germany fdp look fill schaeubles big shoe\n",
      "3       mi school sends welcome back packet warning ki...\n",
      "4       un seek massive aid boost amid rohingya emerge...\n",
      "                              ...                        \n",
      "9979    boom fox news leftist chris wallace attempt tr...\n",
      "9980    list democrat hypocrite voted filibuster gw bu...\n",
      "9981    new fire ravage rohingya village northwest mya...\n",
      "9982    meal wheel shuts lyin lefty truth moveonorgs f...\n",
      "9983    brilliant tucker carlson ayaan hirsi ali discu...\n",
      "Name: lemmatized_text, Length: 9984, dtype: object> \n",
      "\n",
      "tfidf_matrix_train_val: \n",
      " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 13866 stored elements and shape (27321, 2)>\n",
      "  Coords\tValues\n",
      "  (4, 1)\t1.0\n",
      "  (5, 1)\t1.0\n",
      "  (11, 1)\t1.0\n",
      "  (15, 0)\t1.0\n",
      "  (17, 0)\t1.0\n",
      "  (21, 1)\t1.0\n",
      "  (24, 0)\t1.0\n",
      "  (29, 0)\t1.0\n",
      "  (33, 0)\t1.0\n",
      "  (37, 0)\t1.0\n",
      "  (41, 0)\t1.0\n",
      "  (43, 0)\t1.0\n",
      "  (44, 0)\t1.0\n",
      "  (46, 0)\t1.0\n",
      "  (48, 0)\t1.0\n",
      "  (49, 0)\t1.0\n",
      "  (52, 1)\t1.0\n",
      "  (54, 1)\t1.0\n",
      "  (55, 0)\t1.0\n",
      "  (56, 1)\t1.0\n",
      "  (57, 1)\t0.8114463931765621\n",
      "  (57, 0)\t0.5844268568441635\n",
      "  (58, 1)\t1.0\n",
      "  (61, 1)\t1.0\n",
      "  (65, 0)\t1.0\n",
      "  :\t:\n",
      "  (27278, 1)\t0.8114463931765621\n",
      "  (27278, 0)\t0.5844268568441635\n",
      "  (27281, 1)\t1.0\n",
      "  (27283, 0)\t1.0\n",
      "  (27286, 0)\t1.0\n",
      "  (27288, 1)\t1.0\n",
      "  (27289, 0)\t1.0\n",
      "  (27291, 1)\t1.0\n",
      "  (27293, 0)\t1.0\n",
      "  (27294, 0)\t1.0\n",
      "  (27297, 0)\t1.0\n",
      "  (27298, 0)\t1.0\n",
      "  (27299, 0)\t1.0\n",
      "  (27300, 0)\t1.0\n",
      "  (27301, 0)\t1.0\n",
      "  (27302, 0)\t1.0\n",
      "  (27305, 0)\t1.0\n",
      "  (27307, 0)\t1.0\n",
      "  (27308, 0)\t1.0\n",
      "  (27309, 0)\t1.0\n",
      "  (27311, 0)\t1.0\n",
      "  (27312, 0)\t1.0\n",
      "  (27313, 0)\t1.0\n",
      "  (27319, 0)\t1.0\n",
      "  (27320, 1)\t1.0 \n",
      "\n",
      "tfidf_matrix_test: \n",
      " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 2664 stored elements and shape (9984, 2)>\n",
      "  Coords\tValues\n",
      "  (5, 1)\t1.0\n",
      "  (9, 0)\t1.0\n",
      "  (16, 1)\t1.0\n",
      "  (17, 0)\t1.0\n",
      "  (24, 1)\t1.0\n",
      "  (25, 0)\t1.0\n",
      "  (27, 0)\t1.0\n",
      "  (28, 1)\t1.0\n",
      "  (33, 0)\t1.0\n",
      "  (37, 0)\t1.0\n",
      "  (42, 0)\t1.0\n",
      "  (44, 1)\t1.0\n",
      "  (48, 1)\t1.0\n",
      "  (53, 1)\t1.0\n",
      "  (55, 1)\t1.0\n",
      "  (65, 0)\t1.0\n",
      "  (70, 0)\t1.0\n",
      "  (78, 0)\t1.0\n",
      "  (81, 1)\t1.0\n",
      "  (86, 1)\t1.0\n",
      "  (89, 0)\t1.0\n",
      "  (96, 0)\t1.0\n",
      "  (99, 1)\t1.0\n",
      "  (103, 1)\t0.6901773421628135\n",
      "  (103, 0)\t0.7236402672357827\n",
      "  :\t:\n",
      "  (9920, 0)\t1.0\n",
      "  (9922, 0)\t1.0\n",
      "  (9925, 1)\t0.6901773421628135\n",
      "  (9925, 0)\t0.7236402672357827\n",
      "  (9927, 0)\t1.0\n",
      "  (9930, 1)\t1.0\n",
      "  (9934, 1)\t1.0\n",
      "  (9937, 1)\t1.0\n",
      "  (9944, 0)\t1.0\n",
      "  (9946, 0)\t1.0\n",
      "  (9949, 1)\t0.6901773421628135\n",
      "  (9949, 0)\t0.7236402672357827\n",
      "  (9951, 1)\t1.0\n",
      "  (9955, 1)\t1.0\n",
      "  (9956, 1)\t1.0\n",
      "  (9957, 0)\t1.0\n",
      "  (9960, 0)\t1.0\n",
      "  (9963, 0)\t1.0\n",
      "  (9964, 0)\t1.0\n",
      "  (9971, 0)\t1.0\n",
      "  (9979, 1)\t0.4304399335198372\n",
      "  (9979, 0)\t0.9026192240537745\n",
      "  (9982, 1)\t1.0\n",
      "  (9983, 1)\t0.6901773421628135\n",
      "  (9983, 0)\t0.7236402672357827 \n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'toarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_26060\\2669636302.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     29\u001b[39m print(\u001b[33m\"tfidf_matrix_train_val: \\n\"\u001b[39m, tfidf_matrix_train, \u001b[33m\"\\n\"\u001b[39m)\n\u001b[32m     30\u001b[39m print(\u001b[33m\"tfidf_matrix_test: \\n\"\u001b[39m, tfidf_matrix_test, \u001b[33m\"\\n\"\u001b[39m)\n\u001b[32m     31\u001b[39m \n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# count vectorizer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m X_train = count_vectorizer(data_train[\u001b[33m'lemmatized_text'\u001b[39m])\n\u001b[32m     34\u001b[39m X_val = count_vectorizer(data_val[\u001b[33m'lemmatized_text'\u001b[39m])\n\u001b[32m     35\u001b[39m X_test = count_vectorizer(data_test[\u001b[33m'lemmatized_text'\u001b[39m])\n\u001b[32m     36\u001b[39m \n",
      "\u001b[32md:\\ownCloud\\Dokumente\\Ironhack\\week4\\coding\\Natural-Language-Processing-Challenge\\preprocess_data.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m count_vectorizer(data):\n\u001b[32m     54\u001b[39m \n\u001b[32m     55\u001b[39m     bow_vect = CountVectorizer(max_features=\u001b[32m1000\u001b[39m)\n\u001b[32m     56\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bow_vect.fit_transform(data)\n",
      "\u001b[32md:\\ownCloud\\Dokumente\\Ironhack\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6318\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6319\u001b[39m         ):\n\u001b[32m   6320\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6321\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Series' object has no attribute 'toarray'"
     ]
    }
   ],
   "source": [
    " ## preview data\n",
    "#print(data_train.head, \"\\n\")\n",
    "#print(data_test.head, \"\\n\")\n",
    "print(\"Shape train data:\\n\", data_train_val.shape)\n",
    "print(\"Shape test data:\\n\", data_test.shape)\n",
    "\n",
    "# clean data\n",
    "data_train['cleaned_text'] = data_train['text'].apply(clean_text)\n",
    "data_val['cleaned_text'] = data_val['text'].apply(clean_text)\n",
    "data_test['cleaned_text'] = data_test['text'].apply(clean_text)\n",
    "\n",
    "print(\"Cleand text train: \\n\", data_train[\"cleaned_text\"].head, \"\\n\")\n",
    "print(\"Cleand text test: \\n\", data_test[\"cleaned_text\"].head, \"\\n\")\n",
    "\n",
    "\n",
    "## lemmatize data\n",
    "data_train['lemmatized_text'] = data_train['cleaned_text'].apply(lemmatize_text)\n",
    "data_val['lemmatized_text'] = data_val['cleaned_text'].apply(lemmatize_text)\n",
    "data_test['lemmatized_text'] = data_test['cleaned_text'].apply(lemmatize_text)\n",
    "\n",
    "print(\"lemmatized_text train: \\n\", data_train['lemmatized_text'].head, \"\\n\")\n",
    "print(\"lemmatized_text test: \\n\", data_test['lemmatized_text'].head, \"\\n\")\n",
    "\n",
    "# calc tf-idf matrix\n",
    "tfidf_matrix_train = tfidf_vectorization(data_train['lemmatized_text'])\n",
    "tfidf_matrix_val = tfidf_vectorization(data_val['lemmatized_text'])\n",
    "tfidf_matrix_test = tfidf_vectorization(data_test['lemmatized_text'])\n",
    "\n",
    "print(\"tfidf_matrix_train_val: \\n\", tfidf_matrix_train, \"\\n\")\n",
    "print(\"tfidf_matrix_test: \\n\", tfidf_matrix_test, \"\\n\")\n",
    "\n",
    "# count vectorizer\n",
    "X_train = count_vectorizer(data_train['lemmatized_text']).toarray()\n",
    "X_val = count_vectorizer(data_val['lemmatized_text']).toarray()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd044eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## call models\n",
    "model_rf_train(tfidf_matrix_train, tfidf_matrix_val, data_train['label'], data_val['label'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
