{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7985217d",
   "metadata": {},
   "source": [
    "Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8050312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa833e7",
   "metadata": {},
   "source": [
    "Load the files and view first column and first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de1dfc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (68307, 1)\n",
      "Test shape: (19971, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>﻿0\\tdonald trump sends out embarrassing new ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0\\tdrunk bragging trump staffer started russia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0\\tsheriff david clarke becomes an internet jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0\\ttrump is so obsessed he even has obama‚s na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                       <<<<<<< HEAD\n",
       "1  ﻿0\\tdonald trump sends out embarrassing new ye...\n",
       "2  0\\tdrunk bragging trump staffer started russia...\n",
       "3  0\\tsheriff david clarke becomes an internet jo...\n",
       "4  0\\ttrump is so obsessed he even has obama‚s na..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the training data\n",
    "train_df=pd.read_csv(\"data/training_data_lowercase.csv\", \n",
    "                     header=None, names=[\"text\"])\n",
    "#Load the testing data\n",
    "test_df=pd.read_csv(\"data/testing_data_lowercase_nolabels.csv\",\n",
    "                    header=None, names=[\"text\"])\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcbbcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove prefixes and reset row 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef88ae3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿0\\tdonald trump sends out embarrassing new ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0\\tdrunk bragging trump staffer started russia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0\\tsheriff david clarke becomes an internet jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0\\ttrump is so obsessed he even has obama‚s na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0\\tpope francis just called out donald trump d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  ﻿0\\tdonald trump sends out embarrassing new ye...\n",
       "1  0\\tdrunk bragging trump staffer started russia...\n",
       "2  0\\tsheriff david clarke becomes an internet jo...\n",
       "3  0\\ttrump is so obsessed he even has obama‚s na...\n",
       "4  0\\tpope francis just called out donald trump d..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_prefixes=(\"<<<<<<<\",\"=======\",\">>>>>>>\")\n",
    "train_df=train_df[~train_df[\"text\"].str.startswith(bad_prefixes)]\n",
    "test_df=test_df[~test_df[\"text\"].str.startswith(bad_prefixes)]\n",
    "\n",
    "#Reset row index \n",
    "train_df=train_df.reset_index(drop=True)\n",
    "test_df=test_df.reset_index(drop=True)\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c2a796",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393374c0",
   "metadata": {},
   "source": [
    "Tokenization \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e4166",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\n",
    "tokens= word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe98e7a0",
   "metadata": {},
   "source": [
    "Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee2e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens=[token for token in tokens if token.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22285166",
   "metadata": {},
   "source": [
    "Split train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8975c2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_df[\"text\"]\n",
    "y=train_df[\"label\"]\n",
    "\n",
    "X_train,X_val,y_train,y_val=train_test_split(\n",
    "    X,y,test_size=0.2, random_state=42,stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39293657",
   "metadata": {},
   "source": [
    "Feature Extraction TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598420f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer=TfidfVectorizer()\n",
    "\n",
    "#Fit and transform the corpus into a TF-IDF representation\n",
    "X_tfidf=tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "#Show results\n",
    "print(\"TF-IDF:\\n\", X_tfidf.toarray())\n",
    "print(\"Vocabulary:\", tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b7715",
   "metadata": {},
   "source": [
    "Vectorize with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d3443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_pipeline(text):\n",
    "    # Step 1: Tokenize the text\n",
    "    tokens= word_tokenize(text.lower())\n",
    "    # Step 2: Remove stop words\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    tokens=[token for token in tokens if token not in stop_words]\n",
    "    # Step 3: Remove punctuation\n",
    "    tokens=[token for token in tokens if token not in string.punctuation]\n",
    "    # Step 4: Apply lemmatization\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    lemmatized_tokens=[lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b9ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=make_pipeline(\n",
    "    TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        stop_words=\"english\",\n",
    "        ngram_range=(1,2), #try 1-3\n",
    "        min_df=2,\n",
    "        max_df=0.9,\n",
    "        max_features=50000\n",
    "    ),\n",
    "    MultinomialNB(alpha=0.5) #try 0.1 and 1.0\n",
    ")\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704295a6",
   "metadata": {},
   "source": [
    "Evaluate on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_val)\n",
    "print(\"Validation accuracy:\", round(accuracy_score(y_val,y_pred),4))\n",
    "print(classification_report(y_val,y_pred,digits=3))\n",
    "print(confusion_matrix(y_val,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d93ffab",
   "metadata": {},
   "source": [
    "Now train on all data and predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f17e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain on full training data\n",
    "model.fit(train_df[\"text\"], train_df[\"label\"])\n",
    "\n",
    "#Predict labels for test\n",
    "test_pred=model.predict(test_df[\"text\"]).astype(int)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
